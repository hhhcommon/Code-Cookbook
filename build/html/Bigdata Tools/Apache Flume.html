

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>&lt;no title&gt; &mdash; Code-Cookbook 0.1 文档</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/translations.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="&lt;no title&gt;" href="Flink.html" />
    <link rel="prev" title="&lt;no title&gt;" href="Apache%20Druid.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> Code-Cookbook
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">大数据</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Bigdata/index.html">Bigdata</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html">Bigdata Tools</a></li>
</ul>
<p class="caption"><span class="caption-text">博客</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Blogs/index.html">Blogs</a></li>
</ul>
<p class="caption"><span class="caption-text">大数据辅助工具</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Auxiliary%20tools/index.html">Auxiliary tools</a></li>
</ul>
<p class="caption"><span class="caption-text">SQL相关</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../SQL/index.html">SQL</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Code-Cookbook</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">Bigdata Tools</a> &raquo;</li>
        
      <li>&lt;no title&gt;</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/Bigdata Tools/Apache Flume.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <p># Apache Flume</p>
<p>## 概述</p>
<p>&gt; 官网:<a class="reference external" href="http://flume.apache.org/">http://flume.apache.org/</a></p>
<p>&gt; Flume 是 Cloudera 提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的工具。基于流式架构，容错性强，也很灵活简单。
&gt; Flume可以采集文件，socket数据包、文件、文件夹、kafka等各种形式源数据，又可以将采集到的数据(下沉sink)输出到HDFS、hbase、hive、kafka等众多外部存储系统中，一般的采集需求，通过对flume的简单配置即可实现
&gt; Flume针对特殊场景也具备良好的自定义扩展能力，因此，flume可以适用于大部分的日常数据采集场景。</p>
<ul class="simple">
<li><p>Flume是一个海量数据采集的软件。</p></li>
<li><p>Flume是一款来自于apache  java语言软件。</p></li>
<li><p>Flume身世
- 0.9- 属于Cloudera  叫做flume-og
- 1.0+ 属于apache  叫做**flume-ng**</p></li>
</ul>
<p>## 组件架构</p>
<p>1、Flume分布式系统中最核心的角色是agent，agent 本身是一个 Java 进程，一般运行在日志收集节点。flume采集系统就是由一个个agent所连接起来形成。
2、每一个agent相当于一个数据传递员，内部有三个组件：
a)Source：采集组件，用于跟数据源对接，以获取数据
b)Sink：下沉组件，用于往下一级agent传递数据或者往最终存储系统传递数据
c)Channel：传输通道组件，用于从source将数据传递到sink</p>
<p>简单结构</p>
<p>![image-20201024152821463](image-20201024152821463.png)</p>
<p>&gt; Source 到 Channel 到 Sink之间传递数据的形式是Event事件；Event事件是一个数据流单元</p>
<p>复杂结构</p>
<p>多级agent之间串联</p>
<p>![image-20201024192847583](image-20201024192847583.png)</p>
<ul>
<li><p>部署架构</p>
<ul>
<li><p>单agent架构</p>
<p><code class="docutils literal notranslate"><span class="pre">`</span>
<span class="pre">适合简单业务场景</span>&#160; <span class="pre">只需要部署一个agent进程即可</span>
<span class="pre">`</span></code></p>
</li>
<li><p>多agent级联（串联）</p>
<p><code class="docutils literal notranslate"><span class="pre">`</span>
<span class="pre">适合复杂业务场景</span>&#160; <span class="pre">在此场景下</span> <span class="pre">各个agent之间没有地位区别</span> <span class="pre">大家都一样。没有主从之分。</span>
<span class="pre">因为在多台机器部署的</span> <span class="pre">也称之为分布式架构。</span>
<span class="pre">`</span></code></p>
</li>
</ul>
</li>
<li><p>数据流程</p></li>
</ul>
<p>Flume的一般流程是这样的:</p>
<p>source监控某个文件或数据流，数据源产生新的数据，拿到该数据后，将数据封装在一个Event中，并发送到channel后提交，channel队列先进先出，sink去channel队列中拉取数据，然后写入到HDFS/Kafka/或者其他的数据源,甚至是下一个Agent的Source。</p>
<ul>
<li><p>组件</p>
<ul>
<li><p>source</p>
<p><code class="docutils literal notranslate"><span class="pre">`</span>
<span class="pre">对接各个不同的数据源。</span> <span class="pre">采集数据。</span>
<span class="pre">`</span></code></p>
</li>
</ul>
<p>​       常用的Source有:</p>
<p>​     1) exec：可通过tail -f命令去tail一个文件，然后实时同步日志到sink</p>
<p>​     2) spooldir：可监听一个目录，同步目录中的新文件到sink,被同步完的文件可被立即删除或被打上标记。       适合用于同步新文件，但不适合对实时追加日志的文件进行监听并同步。</p>
<p>​     3) taildir：可实时监控一批文件，并记录每个文件最新消费位置，agent进程重启后不会有重复消费的问题</p>
<p>​     4) 支持自定义</p>
<ul>
<li><p>channel</p>
<p><code class="docutils literal notranslate"><span class="pre">`</span>
<span class="pre">就是source和sink之间缓存数据的通道。</span>
<span class="pre">`</span></code></p>
</li>
</ul>
<p>​       Channel是Agent 内部的数据传输通道，用于从 source 将数据传递到 sink；用于桥接Sources和Sinks，      类似于一个队列/缓存。Channel分为:</p>
<p>​      1) Memory Channel是基于内存的,速度快</p>
<p>​      2) File Channel是基于文件的,速度慢,因为会将所有事件写到磁盘,但数据更安全</p>
<ul>
<li><p>sink</p>
<p><code class="docutils literal notranslate"><span class="pre">`</span>
<span class="pre">对接各个不同下沉地(目的地)</span>
<span class="pre">`</span></code></p>
</li>
</ul>
<p>​       Sink是下沉地/目的地，采集数据的传送目的地，用于从Channel收集数据，将数据写到目标源,Sink分为:</p>
<p>​      1) 可以是HDFS、HBase、Kafka等</p>
<p>​      2) 也可以是下一个 FlumeAgent的Source</p>
<p>​      3) 支持自定义</p>
<ul class="simple">
<li><p>结论：上述3个组件就组成了flume的一个java进程。该进程的名字叫做agent。</p></li>
</ul>
</li>
<li><p>Event</p>
<ul>
<li><p>event是flume内部最小的数据单元。</p></li>
<li><p>flume采集的数据都是以event形式存在的。类似于数据包。</p></li>
<li><p>event分为event head /event body 数据都是存储在body中。</p>
<dl class="simple">
<dt><a href="#id1"><span class="problematic" id="id2">``</span></a><a href="#id3"><span class="problematic" id="id4">`</span></a></dt><dd><p>Event: { headers:{} body: 6E 69 68 61 6F 0D                 }</p>
</dd>
</dl>
<p><a href="#id5"><span class="problematic" id="id6">``</span></a><a href="#id7"><span class="problematic" id="id8">`</span></a></p>
</li>
</ul>
</li>
</ul>
<p>### Flume事务</p>
<p>![FlumeTransaction](./ApacheFlume.assets/FlumeTransaction.svg)</p>
<p>#### 数据传输的三大步骤</p>
<ul class="simple">
<li><p>Source从数据源读取数据</p></li>
<li><p>Source将数据**推送**进入Channel</p></li>
<li><p>Sink从Channel中**拉取**数据</p></li>
</ul>
<p>#### Flume如何实现传输数据的完整性、可靠性？</p>
<ul class="simple">
<li><p>数据为什么会丢失（没有事务机制的情况下）？
- Channel是被动的，Source将数据主动推送给Channel，而Sink主动从Channel拉取数据（Take）
- 一般Channel使用MemoryChannel，这样速度更快（FileChannel更安全但是速度慢），但是由于是基于内存，agent宕机的情况下可能导致内存中的数据丢失
- Source端。</p></li>
</ul>
<p>#### Flume的事务机制</p>
<p>##### Put事务</p>
<p>&gt; 顺利的情况下：
&gt;
&gt; Source采集数据调用duPut方法将一批数据（Event）封装在putList中，这批数据成功放入putList中之后，就会调用doCommit方法，将所有的Event放入到Channel中，成功放入就会清空putList。
&gt;
&gt; 问题：
&gt;
&gt; 第一种：
&gt;
&gt; - 如果Sink取出数据的速度过慢，而source放入数据过快，就会造成Channel中数据积压，这个时候putList中的数据就会放不进去，可是已经doCommit了，putList数据丢失了
&gt; - 解决：调用doRollback方法：
&gt;   - 将putList清空，抛出ChannelException
&gt;   - 这个时候Source就会catch到doRollback的异常，Source就会将之前的一批数据重新采集，采集完成之后重新进行事务流程
&gt;
&gt; 第二种：
&gt;
&gt; - 如果Source采集数据使用的是tailDir source，由于某种情况下，监听分源目录被删除了，也会出现问题
&gt; - 解决：调用doRollback来进行事务回滚</p>
<p>##### Take事务</p>
<p>&gt;顺利的情况下：
&gt;
&gt;doTake方法会将Channel中的数据剪切到takeList中，然后等到takeList满后会调用doCommit方法将数据写入目的地，调用doCommit时会进行将数据写入目的地之后再清空takeList
&gt;
&gt;问题：
&gt;
&gt;- 如果出现网络原因导致数据写入到目的地时传输失败了，这个时候如果不进行回滚而置之不理就会导致数据丢失
&gt;
&gt;- 解决：调用doRollback方法来进行回滚，takeList中存有备份数据，takeList中的数据就会原封不动地返还给Channel
&gt;- 新的问题：如果在往目的地Sink数据的时候，刚好Sink“一半”的时候目的机宕机了，在回滚的时候takeList还是将全部数据原封不动返还给Channel，当目的机重新启动上线的时候，再进行Sink操作，这个时候数据就会重复了。<strong>所以从某种程度上来说，使用Flume采集数据不会丢失数据反而会使得数据重复。</strong></p>
<p>## Flume 安装</p>
<ul>
<li><p>提取将JDK配置好</p></li>
<li><p>上传安装包进行解压</p>
<p><code class="docutils literal notranslate"><span class="pre">`shell</span>
<span class="pre">tar</span> <span class="pre">-zxvf</span> <span class="pre">flume-ng-1.6.0-cdh5.14.0.tar.gz</span> <span class="pre">-C</span> <span class="pre">/export/servers/</span>
<span class="pre">`</span></code></p>
</li>
<li><p>配置文件</p>
<p>cd  /export/servers/apache-flume-1.6.0-cdh5.14.0-bin/conf</p>
<p>~~~
cp  flume-env.sh.template flume-env.sh
~~~</p>
<p>vim flume-env.sh</p>
<p><code class="docutils literal notranslate"><span class="pre">`shell</span>
<span class="pre">export</span> <span class="pre">JAVA_HOME=/export/servers/jdk1.8.0_141</span>
<span class="pre">`</span></code></p>
</li>
</ul>
<p>&gt; ​    配置成自己得JDK安装版本和安装目录</p>
<p>## 案例</p>
<p>### 入门案例</p>
<blockquote>
<div><p>~~~</p>
</div></blockquote>
<dl class="simple">
<dt>需求：采集日志文件 如果有数据发送 采集数据打印到控制台。</dt><dd><p>~~~</p>
</dd>
</dl>
<p>#### 配置文件编写</p>
<ul>
<li><p>所谓的采集方案指的就是根据业务需求 确定3个组件的类型和参数。 flume只有根据采集方案文件才指的如何工作。</p></li>
<li><p>确定3个组件</p>
<p><a href="#id9"><span class="problematic" id="id10">``</span></a>`
source: TAILDIR  读取文件</p>
<p>channel:memory channel 缓存在内存中</p>
<p>sink: logger 把数据打印到控制台</p>
<p>基于上述3个类型组件 编写采集方案。
<a href="#id11"><span class="problematic" id="id12">``</span></a><a href="#id13"><span class="problematic" id="id14">`</span></a></p>
</li>
</ul>
<p>cd /export/servers/apache-flume-1.6.0-cdh5.14.0-bin/conf/</p>
<p>vim  console-logger.conf</p>
<p><a href="#id15"><span class="problematic" id="id16">``</span></a><a href="#id17"><span class="problematic" id="id18">`</span></a>properties</p>
<p># Name the components on this agent
# 先定义这个agent中各组件的名字 a1
# 再给3个组件 分别起名字
a1.sources = r1
a1.sinks = k1
a1.channels = c1</p>
<p># Describe/configure the source
# 描述和配置source组件：r1
a1.sources.r1.type = TAILDIR
a1.sources.r1.filegroups = f1
a1.sources.r1.filegroups.f1 = /export/servers/tmp/flume/orderinfo.log</p>
<p># Describe the sink
# 描述和配置source组件：r1
a1.sinks.k1.type = logger</p>
<p># Use a channel which buffers events in memory
# 描述和配置channel组件，此处使用是内存缓存的方式
a1.channels.c1.type = memory
a1.channels.c1.capacity = 1000
a1.channels.c1.transactionCapacity = 100</p>
<p># Bind the source and sink to the channel
# 描述和配置source  channel   sink之间的连接关系
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1
<a href="#id19"><span class="problematic" id="id20">``</span></a><a href="#id21"><span class="problematic" id="id22">`</span></a></p>
<p>&gt; 各组件得名称可以自定义</p>
<p>#### 数据源模拟</p>
<blockquote>
<div><p>模拟日志发送数据</p>
</div></blockquote>
<p>~~~shell
echo “订单金额：100” &gt;&gt; /export/servers/tmp/flume/orderinfo.log
~~~</p>
<p>#### Flume启动命令</p>
<p><a href="#id23"><span class="problematic" id="id24">``</span></a><a href="#id25"><span class="problematic" id="id26">`</span></a>shell
#完整版命令
bin/flume-ng agent –conf conf –conf-file conf/console-logger.conf –name a1 -Dflume.root.logger=INFO,console</p>
<p>#精简版命令
bin/flume-ng agent -c ./conf -f ./conf/console-logger.conf  -n a1 -Dflume.root.logger=INFO,console</p>
<p>#bin/flume-ng agent  固定搭配
#–conf（-c）</p>
<blockquote>
<div><p>指定默认的配置文件路径  要求改路径下 必须有两个文件：flume-env.sh log4j.properties</p>
</div></blockquote>
<dl class="simple">
<dt>#–conf-file  （-f）</dt><dd><p>指定采集方案文件路径</p>
</dd>
<dt>#–name  指定agent的名字 进程名称 （-n）</dt><dd><p>该名称可以随便起 但是要保证和采集方案中一致</p>
</dd>
<dt>#-Dflume.root.logger=INFO,console</dt><dd><p>开启日志 打印更详细的信息 在开发中建议打开</p>
</dd>
</dl>
<p><a href="#id27"><span class="problematic" id="id28">``</span></a><a href="#id29"><span class="problematic" id="id30">`</span></a></p>
<p>&gt; –name         指定agent的名字表示进程名称，一定</p>
<p>### 采集数据到HDFS</p>
<ul>
<li><p>案例1</p>
<ul>
<li><p>需求：某目录下，会不断产生新的文件，每当有新文件出现，就需要把文件采集到 HDFS中去</p></li>
<li><p>确定agent组件</p>
<p><code class="docutils literal notranslate"><span class="pre">`</span>
<span class="pre">source:</span> <span class="pre">TAILDIR</span>
<span class="pre">channel:</span> <span class="pre">memory</span> <span class="pre">channel</span>
<span class="pre">sink:</span>&#160; <span class="pre">HDFS</span> <span class="pre">sink</span>
<span class="pre">`</span></code></p>
</li>
</ul>
</li>
</ul>
<p>#### 配置文件编写</p>
<p>cd /export/servers/apache-flume-1.6.0-cdh5.14.0-bin/conf</p>
<p>vim fileToHdfs.conf</p>
<p>~~~properties
#为我们的source channel  sink起名
a1.sources = r1
a1.channels = c1
a1.sinks = s1
#指定我们的source收集到的数据发送到哪个管道
a1.sources.r1.channels = c1
#指定我们的source数据收集策略
a1.sources.r1.type = TAILDIR
a1.sources.r1.filegroups = f1
a1.sources.r1.filegroups.f1 = /export/servers/tmp/flume/orderinfo.log</p>
<p>#指定我们的channel为memory,即表示所有的数据都装进memory当中
a1.channels.c1.type = memory
#指定我们的sink为kafka  sink，并指定我们的sink从哪个channel当中读取数据
a1.sinks.s1.channel = c1
a1.sinks.s1.type=hdfs
a1.sinks.s1.hdfs.path=hdfs://node1:8020/tmp/flume
a1.sinks.s1.hdfs.fileType=DataStream
~~~</p>
<p>#### 数据源模拟</p>
<blockquote>
<div><p>模拟日志发送数据</p>
</div></blockquote>
<p>~~~shell
echo “订单金额：100” &gt;&gt; /export/servers/tmp/flume/orderinfo.log
~~~</p>
<p>#### Flume启动命令</p>
<p><code class="docutils literal notranslate"><span class="pre">`shell</span>
<span class="pre">#精简版命令</span>
<span class="pre">bin/flume-ng</span> <span class="pre">agent</span> <span class="pre">-c</span> <span class="pre">./conf</span> <span class="pre">-f</span> <span class="pre">./conf/fileToHdfs.conf</span>&#160; <span class="pre">-n</span> <span class="pre">a1</span> <span class="pre">-Dflume.root.logger=INFO,console</span>
<span class="pre">`</span></code></p>
<p>#### 优化配置</p>
<ul>
<li><p>配置参数介绍</p>
<p><a href="#id31"><span class="problematic" id="id32">``</span></a><a href="#id33"><span class="problematic" id="id34">`</span></a>shell
#roll 控制文件以何种形式触发滚动 写入新文件
a1.sinks.k1.hdfs.rollInterval = 3  #以时间间隔控制滚动  默认30 s
a1.sinks.k1.hdfs.rollSize = 20    #以文件大小控制滚动  默认1024 bytes
a1.sinks.k1.hdfs.rollCount = 5    #以event数量控制滚动  默认 10 个</p>
<p>#上述三个都配置的情况下 如果滚动？  谁先满足 谁触发滚动。
#如果不想以某个属性滚动。 就把该属性设置为0  禁用该属性滚动。</p>
<p>#注意事项  如果滚动条件设置不合理 会频繁触发文件切换 会造成大量小文件产生
#在实际开发中 避免小文件产生  最喜欢根据128M大小进行滚动  134217728</p>
<p>#round 是否开启时间上的舍弃  通俗解释：多少时间切换新的文件夹
a1.sinks.k1.hdfs.round = true
a1.sinks.k1.hdfs.roundValue = 10
a1.sinks.k1.hdfs.roundUnit = minute
<a href="#id35"><span class="problematic" id="id36">``</span></a><a href="#id37"><span class="problematic" id="id38">`</span></a></p>
<ul>
<li><p>注意事项  因为在flume中涉及到了动态提取时间**的功能  需要做下面两件事中任一即可：</p>
<p><code class="docutils literal notranslate"><span class="pre">`</span>
<span class="pre">/flume/events/%y-%m-%d/%H%M/</span>
<span class="pre">`</span></code></p>
<ul>
<li><p>开启使用本地时间戳</p>
<p><code class="docutils literal notranslate"><span class="pre">`</span>
<span class="pre">a1.sinks.k1.hdfs.useLocalTimeStamp</span> <span class="pre">=</span> <span class="pre">true</span>
<span class="pre">`</span></code></p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>完整配置文件</p></li>
</ul>
<p>cd /export/servers/apache-flume-1.6.0-cdh5.14.0-bin/conf</p>
<blockquote>
<div><p>vim fileToHdfs2.conf</p>
</div></blockquote>
<p>~~~properties
a1.sources = r1
a1.channels = c1
a1.sinks = s1
#指定channel
a1.sources.r1.channels = c1
#指定我们的source数据收集策略
a1.sources.r1.type = exec
a1.sources.r1.command = tail -f  /export/servers/tmp/flume/test.log</p>
<p>#指定我们的channel为memory,即表示所有的数据都装进memory当中
a1.channels.c1.type = memory
#指定我们的sink到s1，并指定我们的sink从c1当中读取数据
a1.sinks.s1.channel = c1</p>
<p>a1.sinks.s1.type=hdfs
a1.sinks.s1.hdfs.path=hdfs://node1:8020/tmp/flume/%y-%m-%d/%H-%M/
a1.sinks.s1.hdfs.fileType=DataStream</p>
<p>a1.sinks.s1.hdfs.rollInterval = 3
a1.sinks.s1.hdfs.rollSize = 20
a1.sinks.s1.hdfs.rollCount = 5
a1.sinks.s1.hdfs.round = true
a1.sinks.s1.hdfs.roundValue = 10
a1.sinks.s1.hdfs.roundUnit = minute
a1.sinks.s1.hdfs.useLocalTimeStamp = true
a1.sinks.s1.hdfs.filePrefix = test
a1.sinks.s1.hdfs.fileSuffix = log
~~~</p>
<ul>
<li><p>模拟日志增量数据</p>
<ul>
<li><p>日志内容不断增加，需要把采集数据追到日志文件中，并实时写入到 hdfs</p></li>
<li><p>确定3个组件</p>
<p><a href="#id39"><span class="problematic" id="id40">``</span></a>`
source:  exec   #支持在flume中运行shell命令 把命令执行的结果作为数据源进行采集。</p>
<blockquote>
<div><p>shell：tail -f 文件路径</p>
</div></blockquote>
<p>channel: memory channel  基于内存缓存数据
sink: hdfs sink
<a href="#id41"><span class="problematic" id="id42">``</span></a><a href="#id43"><span class="problematic" id="id44">`</span></a></p>
</li>
<li><p>编写增量日志脚本</p>
<p>cd /export/servers/tmp/flume</p>
</li>
</ul>
<p>​        vim shell_log.sh</p>
<p><a href="#id45"><span class="problematic" id="id46">``</span></a><a href="#id47"><span class="problematic" id="id48">`</span></a>shell
while true;do date &gt;&gt; /export/servers/tmp/flume/test.log;sleep 0.5;done</p>
<p>#!/bin/bash
while true
do</p>
<blockquote>
<div><p>date &gt;&gt;  /export/servers/tmp/flume/test.log
sleep 0.5</p>
</div></blockquote>
<p>done
<a href="#id49"><span class="problematic" id="id50">``</span></a><a href="#id51"><span class="problematic" id="id52">`</span></a></p>
</li>
</ul>
<p>&gt; sh脚本赋权限：chmod 755 shell_log.sh</p>
<p>执行脚本：</p>
<p>~~~shell
sh  shell_log.sh
~~~</p>
<p>查看日志：</p>
<p>~~~shell
tail -f /export/servers/tmp/flume/test.log
~~~</p>
<p>启动flume命令：</p>
<p>~~~shell
bin/flume-ng agent -c ./conf -f ./conf/fileToHdfs2.conf  -n a1 -Dflume.root.logger=INFO,console
~~~</p>
<p>### 采集数据到Kafka</p>
<p>#### 配置文件编写</p>
<p>cd /export/servers/apache-flume-1.6.0-cdh5.14.0-bin/conf</p>
<p>vim fileToKafka.conf</p>
<p>~~~properties
#为我们的source channel  sink起名
a1.sources = r1
a1.channels = c1
a1.sinks = k1
#指定我们的source收集到的数据发送到哪个管道
a1.sources.r1.channels = c1
#指定我们的source数据收集策略
a1.sources.r1.type = TAILDIR
a1.sources.r1.filegroups = f1
a1.sources.r1.filegroups.f1 = /export/servers/tmp/flume/orderinfo.log</p>
<p>#指定我们的channel为memory,即表示所有的数据都装进memory当中
a1.channels.c1.type = memory
#指定我们的sink为kafka  sink，并指定我们的sink从哪个channel当中读取数据
a1.sinks.k1.channel = c1
a1.sinks.k1.type = org.apache.flume.sink.kafka.KafkaSink
a1.sinks.k1.kafka.topic = test2
a1.sinks.k1.kafka.bootstrap.servers = node1:9092,node2:9092,node3:9092
a1.sinks.k1.kafka.flumeBatchSize = 20
a1.sinks.k1.kafka.producer.acks = 1
~~~</p>
<p>#### 数据源模拟</p>
<blockquote>
<div><p>模拟日志发送数据</p>
</div></blockquote>
<p>~~~shell
echo “订单金额：100” &gt;&gt; /export/servers/tmp/flume/orderinfo.log
~~~</p>
<p>#### Flume启动命令</p>
<p><code class="docutils literal notranslate"><span class="pre">`shell</span>
<span class="pre">#精简版命令</span>
<span class="pre">bin/flume-ng</span> <span class="pre">agent</span> <span class="pre">-c</span> <span class="pre">./conf</span> <span class="pre">-f</span> <span class="pre">./conf/fileToKafka.conf</span>&#160; <span class="pre">-n</span> <span class="pre">a1</span> <span class="pre">-Dflume.root.logger=INFO,console</span>
<span class="pre">`</span></code></p>
<p>#### kafka消费命令</p>
<p>~~~
bin/kafka-console-consumer.sh –bootstrap-server node1:9092,node2:9092,node3:9092 –topic test2
~~~</p>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="Flink.html" class="btn btn-neutral float-right" title="&lt;no title&gt;" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="Apache%20Druid.html" class="btn btn-neutral float-left" title="&lt;no title&gt;" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; 版权所有 2020-2020, roohom

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>