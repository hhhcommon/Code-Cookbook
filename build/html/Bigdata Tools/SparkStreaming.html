

<!DOCTYPE html>
<html class="writer-html5" lang="zh-CN" >
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>&lt;no title&gt; &mdash; Code-Cookbook 0.1 文档</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/language_data.js"></script>
        <script src="../_static/translations.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="索引" href="../genindex.html" />
    <link rel="search" title="搜索" href="../search.html" />
    <link rel="next" title="1. }" href="StructuredStreaming.html" />
    <link rel="prev" title="&lt;no title&gt;" href="SparkSQL.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home" alt="Documentation Home"> Code-Cookbook
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">大数据</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Bigdata/index.html">Bigdata</a></li>
<li class="toctree-l1"><a class="reference internal" href="index.html">Bigdata Tools</a></li>
</ul>
<p class="caption"><span class="caption-text">博客</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Blogs/index.html">Blogs</a></li>
</ul>
<p class="caption"><span class="caption-text">大数据辅助工具</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../Auxiliary%20tools/index.html">Auxiliary tools</a></li>
</ul>
<p class="caption"><span class="caption-text">SQL相关</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../SQL/index.html">SQL</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Code-Cookbook</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="index.html">Bigdata Tools</a> &raquo;</li>
        
      <li>&lt;no title&gt;</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/Bigdata Tools/SparkStreaming.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <p># Spark Streaming</p>
<p>&lt;script type=”text/javascript” src=”<a class="reference external" href="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default">http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default</a>”&gt;&lt;/script&gt;</p>
<p>&gt; Spark中针对流式数据处理的方案有：
&gt;
&gt; - Spark Streaming
&gt; - Structured Streaming（Spark SQL模块的部分功能：针对流式数据）</p>
<p>&gt; <strong>Spark Streaming与Flink流式计算的本质区别是什么？</strong>
&gt;
&gt; Spark Streaming是基于微批(Micro batch)的，而Flink基于实时流，来一条数据处理一条数据</p>
<p>## 计算思想</p>
<p>&gt; <em>Spark Streaming makes it easy to build scalable fault-tolerent streaming applications.</em></p>
<p>Spark Streaming是Spark生态系统当中一个重要的框架，它建立在Spark Core之上，<strong>Spark Streaming底层就是Spark Core 只不过是划分了微批</strong></p>
<p>对于Spark Streaming来说，将流式数据按照时间间隔BatchInterval划分为很多部分，每一部分
Batch（批次），针对每批次数据Batch当做RDD进行快速分析和处理</p>
<p>它的核心是DStream[^1]，DStream类似于RDD，它实质上一系列的RDD的集合，DStream可以按照秒、分等时间间隔将数据流进行批量的划分。首先从接收到流数据之后，将其划分为多个batch，然后提交给Spark集群进行计算，最后将结果批量输出到HDFS或者数据库以及前端页面展示等等
$$
DStream = Seq[RDD]
$$</p>
<p>[^1]:  DStream(Discretized Stream，离散化数据流，连续不断的数据流)</p>
<p>将流式数据按照【X seconds】划分很多批次Batch，每个Batch数据封装到RDD中进行处理分析，最后每批次数据进行输出</p>
<p>&gt; Notes：对于目前版本的Spark Streaming而言，其最小的Batch Size的选取在0.5~5秒钟之间，所以Spark Streaming能够满足流式准实时计算场景，对实时性要求非常高的如高频实时交易场景则不太适合。</p>
<p>## 编程步骤</p>
<ol class="arabic">
<li><dl class="simple">
<dt>Define the input sources by creating input DStreams.</dt><dd><p>定义从哪个数据源接收流式数据，封装到DStream中</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>Define the streaming computations by applying transformation and output operations to DStreams.</dt><dd><p>针对业务调用DStream中函数，进行数据处理和输出[^2]</p>
</dd>
</dl>
</li>
<li><p>Start receiving data and processing it using streamingContext.start().</p>
<p>streamingContext对象的start()方法开始接收数据</p>
</li>
<li><p>Wait for the processing to be stopped (manually or due to any error) using streamingContext.awaitTermination().</p>
<p>使用streamingContext.awaitTermination()等待程序处理结束（手动或者是报出异常）</p>
</li>
<li><dl class="simple">
<dt>The processing can be manually stopped using streamingContext.stop().</dt><dd><p>启动流式应用，并且一直等待程序终止（人为或异常），最后停止运行</p>
</dd>
</dl>
</li>
</ol>
<p>[^2]:说了一大堆，就第二点最重要，第二点还不会写 :)</p>
<p>## 应用监控</p>
<p>&gt;  当流式处理程序运行时，可以通过主机名+端口号4040访问程序监控页面</p>
<p>![image-20201126161351293](SparkStreaming.assets/image-20201126161351293.png)</p>
<p>TD = SD + PD[^3]</p>
<p>$$
TD = SD + PD
$$</p>
<p>[^3]:每批次Batch数据处理总时间TD = 批次调度延迟时间SD + 批次数据处理时间PT</p>
<ul class="simple">
<li><p>性能衡量：
- 每批次数据处理时间TD &lt;= BatchInterval每批次时间间隔</p></li>
</ul>
<p>## 工作原理</p>
<p>&gt; SparkStreaming处理流式数据时，按照时间间隔划分数据为微批次（Micro-Batch），每批次数据当做RDD，再进行处理分析。</p>
<p>![HowSparkStreamingWorks](SparkStreaming.assets/HowSparkStreamingWorks.svg)</p>
<p>### Streaming Context</p>
<p>当SparkStreaming流式应用启动（streamingContext.start）时，首先创建StreamingContext流式上下文实例对象，整个流式应用环境构建，底层还是SparkContext</p>
<p>当StreamingContext对象构建以后，启动接收器Receiver，专门从数据源端接收数据，<strong>此接收器作为Task任务运行在Executor中，一直运行（Long Runing），一直接收数据</strong></p>
<p>从WEB UI界面【Jobs Tab】可以看到【Job-0】是一个Receiver接收器，一直在运行，以Task方式运行，需要1Core CPU</p>
<p>![image-20201126163124557](SparkStreaming.assets/image-20201126163124557.png)</p>
<p>### Receiver接收数据</p>
<p>启动每个接收器Receiver以后，实时从数据源端接收数据（比如TCP Socket），也是按照时间间隔将接收的流式数据划分为很多**Block**（块）</p>
<p>接收器 Receiver划分流式数据的时间间隔BlockInterval ，<strong>默认值为 200ms</strong>，通过属性【spark.streaming.blockInterval】设置。接收器将接收的数据划分为Block以后，按照设置的存储级别对Block进行存储，从TCP Socket中接收数据默认的存储级别为：MEMORY_AND_DISK_SER_2，先存储内存，不足再存储磁盘，存储2副本</p>
<p>### 汇报接收Blocks</p>
<p>接收器Receiver将实时汇报接收的数据对应的Block信息，当BatchInterval时间达到以后，StreamingContext将对应时间范围内数据block当做RDD，加载SparkContext处理数据</p>
<p>### 重要参数</p>
<ul class="simple">
<li><p>批次时间间隔BatchInterval[^4]
- 每批次数据的时间间隔，每隔多久加载一个Job</p></li>
<li><p>Block时间间隔：BlockInterval
- 接收器划分流式数据的时间间隔，可以调整大小哦，官方建议最小值不能小于50ms
- 默认值为200ms，属性：spark.streaming.blockInterval，调整设置</p></li>
</ul>
<p>[^4]:举个栗子：BatchInterval：1s = 1000ms = 5 * BlockInterval 每批次RDD数据中，有5个Block，每个Block就是RDD一个分区数据</p>
<p>## DStream</p>
<p>&gt; SparkStreaming模块将流式数据封装的数据结构：DStream（Discretized Stream，离散化数据流，连续不断的数据流），代表持续性的数据流和经过各种Spark算子操作后的结果数据流</p>
<p><strong>那么DStream究竟是什么？</strong></p>
<p>&gt; 离散数据流（DStream）是Spark Streaming最基本的抽象。它代表了一种连续的数据流，要么从某种数据源提取数据，要么从其他数据流映射转换而来。DStream内部是由一系列连续的RDD组成的，每个RDD都包含了特定时间间隔内的一批数据</p>
<p><strong>DStream[^5]本质上是一个：一系列时间上连续的RDD（Seq[RDD]）</strong>
$$
DStream = Seq[RDD]
$$</p>
<p>[^5]:DStream相当于一个序列（集合），里面存储的数据类型为RDD（Streaming按照时间间隔划分流式数据）</p>
<p>DStream中每批次数据RDD在处理时，各个RDD之间存在依赖关系，DStream之间也有依赖关系，RDD具有容错性，那么DStream也具有容错性</p>
<p>### 函数</p>
<p>&gt; 主要有两大类：
&gt;
&gt; 一类是将一个DStream转换为另一个DStream的Transformation
&gt;
&gt; 另一类是DStream中每批次RDD经处理输出的Output Operations</p>
<ul class="simple">
<li><p>Transformation函数
- map
- flatmap
- filter
- count
- reduce
- countByKey
- reduceByKey
- union
- join
- cogroup</p></li>
<li><p>Output函数
- print
- saveAsTextFile
- saveAsObjectFiles
- saveAsHadoopFile
- foreachRDD</p></li>
</ul>
<p>&gt; 注意：在DStream中有两个重要的函数，都是针对每批次数据RDD进行操作的，更加接近底层，性能
&gt; 更好，强烈推荐使用
&gt;
&gt; - 转换函数transform：将一个DStream转换为另外一个DStream
&gt;   - [代码模板](<a class="reference external" href="https://github.com/roohom/CodeIndex/blob/main/Spark/Spark-streaming/src/main/scala/me/iroohom/spark/rdd/StreamingTransformRDD.scala">https://github.com/roohom/CodeIndex/blob/main/Spark/Spark-streaming/src/main/scala/me/iroohom/spark/rdd/StreamingTransformRDD.scala</a>)
&gt; - 输出函数foreachRDD：将一个DStream输出到外部存储系统
&gt;   - [代码模板](<a class="reference external" href="https://github.com/roohom/CodeIndex/blob/main/Spark/Spark-streaming/src/main/scala/me/iroohom/spark/output/StreamingOutputRDD.scala">https://github.com/roohom/CodeIndex/blob/main/Spark/Spark-streaming/src/main/scala/me/iroohom/spark/output/StreamingOutputRDD.scala</a>)</p>
<p>### <strong>一个建议</strong></p>
<p>对RDD操作的就不要对DStream操作，当调用DStream中某个函数在RDD中也存在，使用针对RDD操作</p>
<p>## 流式应用状态</p>
<p>SparkStreaming流式计算框架，针对具体业务主要分为三类，使用不同函数进行处理：</p>
<ul class="simple">
<li><p>业务一：无状态Stateless
- 使用[transform](<a class="reference external" href="https://github.com/roohom/CodeIndex/blob/main/Spark/Spark-streaming/src/main/scala/me/iroohom/spark/rdd/StreamingTransformRDD.scala">https://github.com/roohom/CodeIndex/blob/main/Spark/Spark-streaming/src/main/scala/me/iroohom/spark/rdd/StreamingTransformRDD.scala</a>)和[foreacRDD](<a class="reference external" href="https://github.com/roohom/CodeIndex/blob/main/Spark/Spark-streaming/src/main/scala/me/iroohom/spark/output/StreamingOutputRDD.scala">https://github.com/roohom/CodeIndex/blob/main/Spark/Spark-streaming/src/main/scala/me/iroohom/spark/output/StreamingOutputRDD.scala</a>)函数
- 比如实时增量数据ETL：实时从Kafka Topic中获取数据，经过初步转换操作，存储到Elasticsearch索引或HBase表中</p></li>
<li><p>业务二：有状态State
- 双十一大屏幕所有实时累加统计数字（比如销售额和销售量等），比如销售额、网站PV、UV等等
- 函数：[updateStateByKey](<a class="reference external" href="https://github.com/roohom/CodeIndex/blob/main/Spark/Spark-streaming/src/main/scala/me/iroohom/spark/app/state/StreamingUpdateState.scala">https://github.com/roohom/CodeIndex/blob/main/Spark/Spark-streaming/src/main/scala/me/iroohom/spark/app/state/StreamingUpdateState.scala</a>)、[mapWithState](<a class="reference external" href="https://github.com/roohom/CodeIndex/blob/main/Spark/Spark-streaming/src/main/scala/me/iroohom/spark/app/state/StreamingMapWithState.scala">https://github.com/roohom/CodeIndex/blob/main/Spark/Spark-streaming/src/main/scala/me/iroohom/spark/app/state/StreamingMapWithState.scala</a>)</p></li>
<li><p>业务三：窗口统计
- 每隔多久时间统计最近一段时间内数据，比如饿了么后台报表，每隔5分钟统计最近20分钟订单数
- [Window](<a class="reference external" href="https://github.com/roohom/CodeIndex/blob/main/Spark/Spark-streaming/src/main/scala/me/iroohom/spark/app/window/StreamingWindow.scala">https://github.com/roohom/CodeIndex/blob/main/Spark/Spark-streaming/src/main/scala/me/iroohom/spark/app/window/StreamingWindow.scala</a>)</p></li>
</ul>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="StructuredStreaming.html" class="btn btn-neutral float-right" title="1. }" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="SparkSQL.html" class="btn btn-neutral float-left" title="&lt;no title&gt;" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; 版权所有 2020-2020, roohom

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>